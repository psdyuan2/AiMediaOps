#!/usr/bin/env python3
"""
Agentç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•å¿«é€Ÿåˆ›å»ºå’Œä½¿ç”¨Agent
"""

import asyncio
from typing import Any
from pydantic import BaseModel

from app.agents import BaseAgent
from app.core import Context, LLMService


class SimpleResponse(BaseModel):
    """ç®€å•çš„å“åº”æ¨¡å‹"""
    message: str
    success: bool
    data: dict[str, Any]


class MyAgent(BaseAgent):
    """è‡ªå®šä¹‰Agentç¤ºä¾‹"""

    @BaseAgent.tool(name="analyze_data", description="åˆ†æè¾“å…¥æ•°æ®")
    def analyze_data(self, data: str) -> dict[str, Any]:
        """åˆ†ææ•°æ®çš„å·¥å…·"""
        return {
            "input_length": len(data),
            "word_count": len(data.split()),
            "sentiment": "positive" if "å¥½" in data else "neutral"
        }

    @BaseAgent.tool(name="generate_summary", description="ç”Ÿæˆå†…å®¹æ‘˜è¦")
    def generate_summary(self, content: str) -> str:
        """ç”Ÿæˆæ‘˜è¦çš„å·¥å…·"""
        return f"æ‘˜è¦: {content[:50]}..." if len(content) > 50 else f"æ‘˜è¦: {content}"

    async def run(self) -> SimpleResponse:
        """Agentçš„ä¸»æ‰§è¡Œé€»è¾‘"""
        try:
            # ä½¿ç”¨å·¥å…·
            analysis = await self.call_tool("analyze_data", "è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æµ‹è¯•æ•°æ®")
            summary = await self.call_tool("generate_summary", "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æµ‹è¯•å†…å®¹ï¼Œç”¨æ¥æµ‹è¯•å·¥å…·åŠŸèƒ½å’ŒAgentç³»ç»Ÿçš„é›†æˆæ•ˆæœ")

            # ä½¿ç”¨LLMç”Ÿæˆå“åº”
            llm_response = await self.llm.generate(
                prompt="ä½œä¸ºAIåŠ©æ‰‹ï¼Œæ€»ç»“ä½ åˆšåˆšæ‰§è¡Œçš„æ“ä½œ",
                response_model=SimpleResponse,
                system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„AI Agent"
            )

            return llm_response

        except Exception as e:
            return SimpleResponse(
                message=f"æ‰§è¡Œå¤±è´¥: {e}",
                success=False,
                data={"error": str(e)}
            )


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Agentç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹")
    print("=" * 40)

    # åˆå§‹åŒ–ç»„ä»¶
    llm_service = LLMService()
    context = Context.create_new("æ¼”ç¤ºAgentåŠŸèƒ½")

    # åˆ›å»ºAgent
    agent = MyAgent(context, llm_service)
    print(f"âœ… Agentåˆ›å»ºæˆåŠŸ: {agent}")
    print(f"ğŸ”§ å¯ç”¨å·¥å…·: {agent.list_tools()}")

    # è¿è¡ŒAgent
    print("\nğŸ¤– è¿è¡ŒAgent...")
    result = await agent.run()

    print(f"\nğŸ“‹ æ‰§è¡Œç»“æœ:")
    print(f"æ¶ˆæ¯: {result.message}")
    print(f"æˆåŠŸ: {result.success}")
    print(f"æ•°æ®: {result.data}")

    print(f"\nâœ¨ ç¤ºä¾‹å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(main())